{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore') #Apaga las warnings, no hay errores, solo tira un monton de mensajes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(k,filename,swp,shp,file_extension,Fs):\n",
    "    #Lee archivo json o psimesh\n",
    "    data_all=pd.DataFrame()\n",
    "\n",
    "    if file_extension=='.psimesh':\n",
    "        response = open(filename,encoding = 'utf-8')\n",
    "    else:\n",
    "        response = open(filename)\n",
    "    data_read = json.load(response)\n",
    "   \n",
    "    #Lee todos los trials. Queda todo junto.\n",
    "    hoja=0\n",
    "    are_trials=True\n",
    "    while are_trials:\n",
    "        try:\n",
    "            try:\n",
    "                data = json_normalize(data_read[\"stimData\"][hoja][\"eyetrackerData\"])\n",
    "                data[\"Trial\"]=hoja+1\n",
    "                data_all=pd.concat([data_all,data],axis=0,ignore_index=True)\n",
    "                hoja=hoja+1\n",
    "            except:\n",
    "                trial = 'trial'+str(hoja+1)\n",
    "                data = json_normalize(data_read[\"all\"][trial][\"data\"])\n",
    "                data[\"Trial\"]=hoja+1\n",
    "                data_all=pd.concat([data_all,data],axis=0,ignore_index=True)\n",
    "                hoja=hoja+1\n",
    "        except:\n",
    "            are_trials=False\n",
    "            break\n",
    "    data=data_all.copy()    \n",
    "\n",
    "    #Grilla temporal. No es uniforme. Arranca en cero\n",
    "    t1=np.asarray(data[\"t\"]-data[\"t\"][0])\n",
    "    if np.all(data[\"x\"]<=1):\n",
    "        x1=np.asarray(data[\"x\"]*swp)\n",
    "        y1=np.asarray(data[\"y\"]*shp)\n",
    "    else:\n",
    "        x1=np.asarray(data[\"x\"])\n",
    "        y1=np.asarray(data[\"y\"])\n",
    "    \n",
    "    if 'trialScores' in data_read:\n",
    "        (head,file2)=os.path.split(filename)\n",
    "        file1=os.path.splitext(file2)\n",
    "        file_out=os.path.join(directory_out, \"trialscores\" + \"_\" + file1[0] + \".txt\")\n",
    "        sourceFile = open(file_out, 'w')\n",
    "        print(data_read['trialScores'], file = sourceFile)\n",
    "        sourceFile.close()\n",
    "    if 'eventLog' in data_read:\n",
    "        file_out=os.path.join(directory_out, \"eventlog\" + \"_\" + file1[0] + \".txt\")\n",
    "        sourceFile = open(file_out, 'w')\n",
    "        print(data_read['eventLog'], file = sourceFile)\n",
    "        sourceFile.close()     \n",
    "  \n",
    "    #Arregla la duración de los trials del Ret, que el archivo no coincide con lo visto en el PsiMesh.\n",
    "    #También reescalea a la pantalla correcta (los datos están 'corridos')\n",
    "    (head,file2)=os.path.split(filename)\n",
    "    files_xlsx=glob.glob(head + 'Duration_trials.xlsx')\n",
    "    if len(files_xlsx) !=0:\n",
    "        time_trials = pd.read_excel (files_xlsx,engine='openpyxl')\n",
    "        ntrials=data[\"Trial\"][t1.size-1]\n",
    "        t1p=np.linspace(0,time_trials[ntrials][k],num=t1.size)\n",
    "        n=0\n",
    "        trials=0\n",
    "        while n<t1.size:\n",
    "            if t1p[n]<=time_trials[trials][k]:\n",
    "                data[\"Trial\"][n]=trials+1\n",
    "                n=n+1\n",
    "            else:\n",
    "                trials=trials+1\n",
    "            if trials==ntrials+1:\n",
    "                break\n",
    "    \n",
    "    #Interpola x1 e y1 lineal para la grilla del tiempo uniforme\n",
    "    #Renormaliza la grilla temporal uniforme a la frecuencia del eye-tracker\n",
    "    step=int(1000/Fs)\n",
    "    t2=np.arange(t1[0],t1[t1.size-1],step)\n",
    "    fin=t2.size\n",
    "    dfc = np.zeros(fin,dtype={\"names\":('t','xp','yp','trial','interp'),'formats':('float','float','float','int','int')})\n",
    "    fx = interp1d(t1, x1, kind='linear',fill_value='extrapolate')\n",
    "    fy = interp1d(t1, y1, kind='linear',fill_value='extrapolate')\n",
    "    x2 = fx(t2)\n",
    "    y2 = fy(t2)\n",
    "    dfc[\"t\"]=t2\n",
    "    dfc[\"xp\"]=x2 \n",
    "    dfc[\"yp\"]=y2 \n",
    "    \n",
    "    #Trials originales\n",
    "    trials_data=data[\"Trial\"]\n",
    "    indx_trial_data=np.diff(trials_data)\n",
    "    res=np.array(np.where(indx_trial_data!=0))\n",
    "    res=np.squeeze(res,0)\n",
    "    tchange=t1[res]\n",
    "    tchange=np.insert(tchange,0,0)\n",
    "    tchange=np.append(tchange,t2[t2.size-1]+1)\n",
    "    #Corrige los trials con la nueva grilla de tiempo\n",
    "    i=0\n",
    "    n=0\n",
    "    while n<t2.size:\n",
    "        if t2[n]>=tchange[i] and t2[n]<tchange[i+1]:\n",
    "            if i<res.size:\n",
    "                dfc[\"trial\"][n]=data[\"Trial\"][res[i]]\n",
    "            else:\n",
    "                dfc[\"trial\"][n]=data[\"Trial\"][t1.size-1]\n",
    "            n=n+1\n",
    "        else:\n",
    "            i=i+1\n",
    "            if i==res.size+1:\n",
    "                break\n",
    "                \n",
    "    #Indica los puntos donde hay más de 100 ms seguidos interpolados           \n",
    "    for n in range(0,t1.size-1,1):\n",
    "        if t1[n+1]-t1[n]>100:\n",
    "            dfc[\"interp\"][(t1[n]<=t2) & (t2<=t1[n+1])]=-1\n",
    "    \n",
    "    #Pasa el (0,0) de las coordenadas al centro de la pantalla\n",
    "    dfc[\"xp\"]=dfc[\"xp\"]-swp/2\n",
    "    dfc[\"yp\"]=dfc[\"yp\"]-shp/2       \n",
    "    \n",
    "    #Corrige la posición del Ret que no está bien calibrado. Hay que hacerlo después de la transformación al (0,0)\n",
    "    if len(files_xlsx) !=0:\n",
    "        xa=time_trials[\"xa\"][k]\n",
    "        ya=time_trials[\"ya\"][k]\n",
    "        yfact=time_trials[\"facty\"][k]\n",
    "        dfc[\"xp\"]=dfc[\"xp\"]-xa\n",
    "        dfc[\"yp\"]=(dfc[\"yp\"]-ya)*yfact\n",
    "            \n",
    "    #Guarda en dataframe        \n",
    "    df=pd.DataFrame(dfc)\n",
    "    \n",
    "    #Cierra archivo .json o .psimesh\n",
    "    response.close()\n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Acomoda los datos en una matriz, chequea onset y offset de sacadas, saca tamaños y duraciones.\n",
    "def data_to_frame(df_int,index_onset,index_offset):\n",
    "    \n",
    "    w_interp=df_int[\"vpr\"]\n",
    "    \n",
    "    t=df_int[\"t\"]\n",
    "    theta_sz=t.size\n",
    "    data = np.zeros(theta_sz,dtype={\"names\":('t','xp','vpx','yp','vpy','event','trial','interp'),'formats':('float','float','float','float','float','int','int','int')})\n",
    "    data[\"t\"]=t\n",
    "    data[\"xp\"]=df_int[\"xp\"]\n",
    "    data[\"yp\"]=df_int[\"yp\"]\n",
    "    data[\"trial\"]=df_int[\"trial\"]\n",
    "    data[\"interp\"]=df_int[\"interp\"]\n",
    "    data[\"vpx\"]=df_int[\"vpx\"]\n",
    "    data[\"vpy\"]=df_int[\"vpy\"]\n",
    "    \n",
    "    #Llena con 0 fijaciones y 1 sacadas. Esto ya fusiona sacadas 'superpuestas'\n",
    "    nsac=index_onset.size\n",
    "    data[\"event\"][:]=0\n",
    "    for j in range(0,nsac,1):\n",
    "            data[\"event\"][index_onset[j]-1:index_offset[j]]=1\n",
    "    \n",
    "    #Busca nuevos Onset y offset de SACADAS\n",
    "    index_onset=np.array(np.where(np.diff(data[\"event\"])==1))+1\n",
    "    index_offset=np.array(np.where(np.diff(data[\"event\"])==-1))\n",
    "    \n",
    "    index_onset=np.squeeze(index_onset,0)\n",
    "    index_offset=np.squeeze(index_offset,0)\n",
    "    \n",
    "    if data[\"event\"][0]==1:\n",
    "        index_onset = np.hstack([0, index_onset])\n",
    "            \n",
    "    nsac=index_onset.size\n",
    "    for n in range(1,nsac):\n",
    "        fix=t[index_onset[n]-1]-t[index_offset[n-1]+1]\n",
    "        sac=t[index_offset[n]]-t[index_onset[n]]\n",
    "        #Fusiona sacadas si entre ellas hay una fijación de duración menor o igual a 20 ms\n",
    "        if fix<=20:\n",
    "            data[\"event\"][index_offset[n-1]+1:index_onset[n]]=1\n",
    "            index_onset[n]=index_onset[n-1]\n",
    "            index_onset[n-1]=-1\n",
    "            index_offset[n-1]=-1\n",
    "        #Fusiona fijaciones si entre ellas hay una sacada de duración menor o igual a 20 ms\n",
    "        if sac<=20:\n",
    "            data[\"event\"][index_onset[n]:index_offset[n]]=0\n",
    "            index_onset[n]=-1\n",
    "            index_offset[n]=-1\n",
    "        #Borra eventos donde hay Nan (no hay datos)\n",
    "        if np.any(np.isnan(data[\"xp\"][index_onset[n]:index_offset[n]])):\n",
    "            index_onset[n]=-1\n",
    "            index_offset[n]=-1\n",
    "        \n",
    "    #print(index_offset)\n",
    "    data_frame=pd.DataFrame(data)\n",
    "    \n",
    "    return (index_onset,index_offset,data_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Acomoda los datos en una matriz, chequea onset y offset de sacadas, saca tamaños y duraciones.\n",
    "def saccades_to_frame(df_int,index_onset,index_offset):\n",
    "    w_peaks1_sz=index_onset.size\n",
    "    saccades = np.zeros(w_peaks1_sz,dtype={\"names\":('number','onset', 'offset','sizep','duration','wpeak','trial'),\n",
    "                          'formats':('int','int', 'int','float','float','float','int')})\n",
    "    \n",
    "    w_interp=df_int[\"vpr\"]\n",
    "    x=df_int[\"xp\"]\n",
    "    y=df_int[\"yp\"]\n",
    "    \n",
    "    t=df_int[\"t\"]\n",
    "    dsize=t.size\n",
    "    n=0\n",
    "    while n<w_peaks1_sz:\n",
    "        #Si hubo algún problema de detección de onset u offset se marcó con -1 y se pasa de largo.\n",
    "        if index_onset[n] == -1:\n",
    "            saccades[\"number\"][n]=0\n",
    "            n=n+1\n",
    "            continue\n",
    "        if index_offset[n] == -1:\n",
    "            saccades[\"number\"][n]=0\n",
    "            n=n+1\n",
    "            continue\n",
    "        saccades[\"number\"][n]=n+1\n",
    "        saccades[\"onset\"][n]=index_onset[n]\n",
    "        saccades[\"offset\"][n]=index_offset[n]\n",
    "        saccades[\"sizep\"][n]=np.sqrt((x[index_offset[n]]-x[index_onset[n]])**2+(y[index_offset[n]]-y[index_onset[n]])**2)\n",
    "        w_peaks, _ = find_peaks(w_interp[saccades[\"onset\"][n]:saccades[\"offset\"][n]])\n",
    "        if w_peaks.size==0:\n",
    "            saccades[\"wpeak\"][n]=np.amax(w_interp[saccades[\"onset\"][n]:saccades[\"offset\"][n]])\n",
    "        else:\n",
    "            saccades[\"wpeak\"][n]=np.amax(w_interp[w_peaks+saccades[\"onset\"][n]])\n",
    "        saccades[\"duration\"][n]=np.abs(t[index_offset[n]]-t[index_onset[n]])\n",
    "        n+=1\n",
    "       \n",
    "    saccades1=np.delete(saccades, np.where(saccades[\"number\"] == 0), axis=0)\n",
    "    nsac=saccades1.size\n",
    "    saccades1[\"number\"][:]=np.arange(nsac)\n",
    "    \n",
    "    #Trials from data\n",
    "    trials_data=df_int[\"trial\"]\n",
    "    indx_trial_data=np.diff(trials_data)\n",
    "    res=np.array(np.where(indx_trial_data!=0))\n",
    "    res=np.squeeze(res,0)\n",
    "    ntrials=res.size\n",
    "    fin_trial=np.zeros(ntrials,dtype='int')\n",
    "    fin_trial[0:ntrials-1]=res[0:ntrials-1];\n",
    "    fin_trial[-1]=dsize-1;\n",
    "    ini_trial=np.zeros(ntrials,dtype='int');\n",
    "    ini_trial[0]=0;\n",
    "    ini_trial[1:ntrials]=fin_trial[0:ntrials-1]+1;\n",
    "    \n",
    "    trial=0\n",
    "    n=0\n",
    "    while trial<ntrials:\n",
    "        while n<nsac:\n",
    "            j0=ini_trial[trial]\n",
    "            jf=fin_trial[trial]\n",
    "            if saccades1[\"offset\"][n]<=jf and saccades1[\"onset\"][n]>=j0:\n",
    "                saccades1[\"trial\"][n]=trials_data[saccades1[\"onset\"][n]]\n",
    "                n=n+1\n",
    "                continue\n",
    "            if saccades1[\"offset\"][n]>jf and saccades1[\"onset\"][n]>j0 and saccades1[\"onset\"][n]<=jf:\n",
    "                saccades1[\"trial\"][n]=trials_data[saccades1[\"onset\"][n]]\n",
    "                n=n+1\n",
    "                continue\n",
    "            if saccades1[\"offset\"][n]>jf and saccades1[\"onset\"][n]>jf: \n",
    "                trial=trial+1\n",
    "                continue\n",
    "        if n==nsac:\n",
    "            break\n",
    "    \n",
    "    saccades_frame=pd.DataFrame(saccades1)\n",
    "    \n",
    "    return (saccades_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Acomoda los datos en una matriz, chequea onset y offset de sacadas, saca tamaños y duraciones.\n",
    "def fix_to_frame(df_int,saccades_frame):\n",
    "    index_onset=saccades_frame[\"onset\"]\n",
    "    index_offset=saccades_frame[\"offset\"]\n",
    "    nsize=index_onset.size\n",
    "    fix = np.zeros(nsize+1,dtype={\"names\":('number','onset','offset','duration','avg_loc_x','avg_loc_y','trial'),\n",
    "                                  'formats':('int','int','int','float','float','float','int')})\n",
    "\n",
    "    x=df_int[\"xp\"]\n",
    "    y=df_int[\"yp\"]\n",
    "    \n",
    "    t=df_int[\"t\"]\n",
    "    dsize=t.size\n",
    "    n=0\n",
    "    while n<nsize+1:\n",
    "        fix[\"number\"][n]=n\n",
    "        if n==0:\n",
    "            if index_onset[0] !=0:\n",
    "                fix[\"onset\"][n]=0\n",
    "                fix[\"offset\"][n]=index_onset[n]-1\n",
    "                fix[\"avg_loc_x\"][n]=np.mean(x[0:index_onset[n]-1])\n",
    "                fix[\"avg_loc_y\"][n]=np.mean(y[0:index_onset[n]-1])\n",
    "                fix[\"duration\"][n]=t[index_onset[n]-1]-t[0]\n",
    "        if 0<n<nsize:\n",
    "            fix[\"onset\"][n]=index_offset[n-1]+1\n",
    "            fix[\"offset\"][n]=index_onset[n]-1\n",
    "            fix[\"avg_loc_x\"][n]=np.mean(x[index_offset[n-1]+1:index_onset[n]-1])\n",
    "            fix[\"avg_loc_y\"][n]=np.mean(y[index_offset[n-1]+1:index_onset[n]-1])\n",
    "            fix[\"duration\"][n]=t[index_onset[n]-1]-t[index_offset[n-1]+1]\n",
    "        if index_offset[nsize-1] != dsize-1:\n",
    "            if n==nsize:\n",
    "                fix[\"onset\"][n]=index_offset[n-1]+1\n",
    "                fix[\"offset\"][n]=dsize-1\n",
    "                fix[\"avg_loc_x\"][n]=np.mean(x[index_offset[n-1]+1:dsize-1])\n",
    "                fix[\"avg_loc_y\"][n]=np.mean(y[index_offset[n-1]+1:dsize-1])\n",
    "                fix[\"duration\"][n]=t[dsize-1]-t[index_offset[n-1]+1]\n",
    "        n+=1\n",
    "            \n",
    "    #Trials from data\n",
    "    trials_data=df_int[\"trial\"]\n",
    "    indx_trial_data=np.diff(trials_data)\n",
    "    res=np.array(np.where(indx_trial_data!=0))\n",
    "    res=np.squeeze(res,0)\n",
    "    ntrials=res.size\n",
    "    fin_trial=np.zeros(ntrials,dtype='int')\n",
    "    fin_trial[0:ntrials-1]=res[0:ntrials-1];\n",
    "    fin_trial[-1]=dsize-1;\n",
    "    ini_trial=np.zeros(ntrials,dtype='int');\n",
    "    ini_trial[0]=0;\n",
    "    ini_trial[1:ntrials]=fin_trial[0:ntrials-1]+1;\n",
    "    \n",
    "    trial=0\n",
    "    n=0\n",
    "    while trial<ntrials:\n",
    "        while n<nsize+1:\n",
    "            j0=ini_trial[trial]\n",
    "            jf=fin_trial[trial]\n",
    "            if fix[\"offset\"][n]<=jf and fix[\"onset\"][n]>=j0:\n",
    "                fix[\"trial\"][n]=trials_data[fix[\"onset\"][n]]\n",
    "                n=n+1\n",
    "                continue\n",
    "            if fix[\"offset\"][n]>jf and fix[\"onset\"][n]>j0 and fix[\"onset\"][n]<=jf:\n",
    "                fix[\"trial\"][n]=trials_data[fix[\"onset\"][n]]\n",
    "                n=n+1\n",
    "                continue\n",
    "            if fix[\"offset\"][n]>jf and fix[\"onset\"][n]>jf: \n",
    "                trial=trial+1\n",
    "                continue\n",
    "        if n==nsize+1:\n",
    "            break\n",
    "    \n",
    "    fix_frame=pd.DataFrame(fix)\n",
    "    \n",
    "    return (fix_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lee archivo csv\n",
    "def read_csv(filename,init,fin):\n",
    "    data = pd.read_csv (filename,decimal=\",\", delimiter=\";\")\n",
    "    #Cambia las comas por puntos, sino no los puede cambiar a float\n",
    "    data['LEFT_GAZE_X'] = [str(x).replace(',', '.') for x in data['LEFT_GAZE_X']]\n",
    "    data['LEFT_GAZE_Y'] = [str(x).replace(',', '.') for x in data['LEFT_GAZE_Y']]\n",
    "    data['RIGHT_GAZE_X'] = [str(x).replace(',', '.') for x in data['RIGHT_GAZE_X']]\n",
    "    data['RIGHT_GAZE_Y'] = [str(x).replace(',', '.') for x in data['RIGHT_GAZE_Y']]\n",
    "    #Cambia las columnas objeto a float\n",
    "    s=pd.Series(data[\"LEFT_GAZE_X\"])\n",
    "    data[\"LEFT_GAZE_X\"] = pd.to_numeric(s, errors='coerce')\n",
    "    s=pd.Series(data[\"LEFT_GAZE_Y\"])\n",
    "    data[\"LEFT_GAZE_Y\"] = pd.to_numeric(s, errors='coerce')\n",
    "    s=pd.Series(data[\"RIGHT_GAZE_X\"])\n",
    "    data[\"RIGHT_GAZE_X\"] = pd.to_numeric(s, errors='coerce')\n",
    "    s=pd.Series(data[\"RIGHT_GAZE_Y\"])\n",
    "    data[\"RIGHT_GAZE_Y\"] = pd.to_numeric(s, errors='coerce')\n",
    "    #Cambio el tiempo TIMESTAMP para que empiece de cero (ms)\n",
    "    data[\"TIMESTAMP\"]=data[\"TIMESTAMP\"]-data[\"TIMESTAMP\"][init]\n",
    "    #Tomo una parte del experimento para procesar. Guardo tiempo en t,horizontal en x y vertical en y, \n",
    "    #promediados en binocular\n",
    "    t=data [\"TIMESTAMP\"][init:fin]\n",
    "    x=(data[\"LEFT_GAZE_X\"][init:fin]+data[\"RIGHT_GAZE_X\"][init:fin])/2\n",
    "    y=(data[\"LEFT_GAZE_Y\"][init:fin]+data[\"RIGHT_GAZE_Y\"][init:fin])/2\n",
    "    \n",
    "    nz=t.size\n",
    "    dfc = np.zeros(nz,dtype={\"names\":('t','xp','yp','trial','interp'),'formats':('float','float','float','int','int')})\n",
    "    dfc[\"t\"]=t\n",
    "    dfc[\"xp\"]=x\n",
    "    dfc[\"yp\"]=y\n",
    "    \n",
    "    df=pd.DataFrame(dfc)\n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imprime _frame a un archivo csv\n",
    "def print_to_csv(saccades_frame,fix_frame,data_frame,filename1,filename2,filename3):\n",
    "    saccades_frame.to_csv (filename1,  header=True, index=False)\n",
    "    fix_frame.to_csv (filename2,  header=True, index=False)\n",
    "    data_frame.to_csv (filename3,  header=True, index=True)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lee _frame de un archivo csv\n",
    "def read_to_csv(filename1,filename2):\n",
    "    saccades = pd.read_csv (filename1)\n",
    "    data = pd.read_csv (filename2)\n",
    "    return (saccades,data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
